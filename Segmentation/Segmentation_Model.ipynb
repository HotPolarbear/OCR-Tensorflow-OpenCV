{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in /Users/hotpolarbear/Documents/Programs/Projects/.venv/lib/python3.9/site-packages (11.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hotpolarbear/Documents/Programs/Projects/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from numpy import asarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"/Users/hotpolarbear/Documents/Programs/Projects/OCR/Segmentation/Sample_Image_02.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "blur = cv2.GaussianBlur(gray, (3,3), 0)\n",
    "\n",
    "\n",
    "thresh = cv2.threshold(blur, 100,255 ,cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 10))\n",
    "dilate = cv2.dilate(thresh, kernel , iterations = 1)\n",
    "\n",
    "\n",
    "cnts = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts =cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "cnts = sorted(cnts, key = lambda x : cv2.boundingRect(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list=['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.models.load_model(\"/Users/hotpolarbear/Documents/Programs/Projects/OCR/Training/OCR_N_25M_9181.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-22 13:33:15.158 Python[52539:12913823] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2025-01-22 13:33:15.158 Python[52539:12913823] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 128, 128)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n",
      "highest accuracy 0.99999523\n",
      "(1, 128, 128)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "highest accuracy 0.39235577\n",
      "(1, 128, 128)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "highest accuracy 0.9353859\n",
      "(1, 128, 128)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "highest accuracy 0.9353859\n",
      "(1, 128, 128)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "highest accuracy 0.6974366\n"
     ]
    }
   ],
   "source": [
    "ans =\"\"\n",
    "\n",
    "for c in cnts:\n",
    "    x,y,w,h = cv2.boundingRect(c)\n",
    "    if h>20 and w >2 :\n",
    "        roi = image[y:y+h, x:x+w]\n",
    "        cv2.rectangle(image, (x,y), (x+w, y+h), (36,255,12), 2)\n",
    "        cv2.imshow(\"Image\", roi); cv2.waitKey(0); cv2.destroyAllWindows(); cv2.waitKey(1)\n",
    "        img=cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "        _, img = cv2.threshold(img, 100, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "        img = cv2.resize(img, (128, 128))\n",
    "        #img = tf.convert_to_tensor(img)\n",
    "        img=img/255.0\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        '''x = asarray(img)\n",
    "        x = x.astype('float32')/255.0\n",
    "\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        \n",
    "        x = np.where(x=='True', 1, x)\n",
    "        x = np.where(x=='False', 0, x)\n",
    "        \n",
    "        print(type(x))'''\n",
    "        print(img.shape)\n",
    "\n",
    "\n",
    "        ocr_result = model.predict(img)\n",
    "\n",
    "        print(\"highest accuracy \" + str(ocr_result.max()))\n",
    "        max = ocr_result.max()\n",
    "        index = ocr_result.argmax()\n",
    "\n",
    "        ans = ans + str((label_list[index]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'H9IIO'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
